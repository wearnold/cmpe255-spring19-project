{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os import walk, getcwd\n",
    "#import h5py\n",
    "\n",
    "##All npy files are stored in the train_data folder:\n",
    "mypath = \"./train_data/\"\n",
    "txt_name_list = []\n",
    "for (dirpath, dirnames, filenames) in walk(mypath):\n",
    "    if filenames != '.DS_Store':       ##Ugh mac junk\n",
    "        txt_name_list.extend(filenames)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txt_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "xtotal = []\n",
    "ytotal = []\n",
    "slice_train = int(80000/len(txt_name_list))  ###Setting value to be 80000 for the final dataset\n",
    "i = 0\n",
    "seed = np.random.randint(1, 10e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creates test/train split with quickdraw data\n",
    "for txt_name in txt_name_list:\n",
    "    txt_path = mypath + txt_name\n",
    "    x = np.load(txt_path)\n",
    "    x = x.astype('float32') / 255.    ##scale images\n",
    "    y = [i] * len(x)  \n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(x)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(y)\n",
    "    x = x[:slice_train]\n",
    "    y = y[:slice_train]\n",
    "    if i != 0: \n",
    "        xtotal = np.concatenate((x,xtotal), axis=0)\n",
    "        ytotal = np.concatenate((y,ytotal), axis=0)\n",
    "    else:\n",
    "        xtotal = x\n",
    "        ytotal = y\n",
    "    i += 1\n",
    "x_train, x_test, y_train, y_test = train_test_split(xtotal, ytotal, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes:  345\n",
      "\n",
      "original x_train shape: (63756, 784)\n",
      "original x_test shape: (15939, 784)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = len(txt_name_list)\n",
    "epochs = 25\n",
    "\n",
    "# to show\n",
    "print('Num classes: ', num_classes)\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print('\\noriginal x_train shape:', x_train.shape)\n",
    "print('original x_test shape:', x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (63756, 28, 28, 1)\n",
      "63756 train samples\n",
      "15939 test samples\n"
     ]
    }
   ],
   "source": [
    "# Based on previous shape\n",
    "x_train = x_train.reshape(x_train.shape[0],28,28,1)\n",
    "x_test = x_test.reshape(x_test.shape[0],28,28,1)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\wayne\\envs\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\wayne\\envs\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\wayne\\envs\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 63756 samples, validate on 15939 samples\n",
      "Epoch 1/25\n",
      "63756/63756 [==============================] - 199s 3ms/step - loss: 5.2128 - acc: 0.0454 - val_loss: 4.0850 - val_acc: 0.1739\n",
      "Epoch 2/25\n",
      "63756/63756 [==============================] - 206s 3ms/step - loss: 4.1589 - acc: 0.1552 - val_loss: 3.5085 - val_acc: 0.2820\n",
      "Epoch 3/25\n",
      "63756/63756 [==============================] - 193s 3ms/step - loss: 3.6721 - acc: 0.2258 - val_loss: 3.0812 - val_acc: 0.3421\n",
      "Epoch 4/25\n",
      "63756/63756 [==============================] - 193s 3ms/step - loss: 3.4133 - acc: 0.2667 - val_loss: 2.9547 - val_acc: 0.3655\n",
      "Epoch 5/25\n",
      "63756/63756 [==============================] - 192s 3ms/step - loss: 3.2312 - acc: 0.2986 - val_loss: 2.8097 - val_acc: 0.3815\n",
      "Epoch 6/25\n",
      "63756/63756 [==============================] - 192s 3ms/step - loss: 3.1074 - acc: 0.3194 - val_loss: 2.7446 - val_acc: 0.4075\n",
      "Epoch 7/25\n",
      "63756/63756 [==============================] - 191s 3ms/step - loss: 2.9952 - acc: 0.3358 - val_loss: 2.7226 - val_acc: 0.3983\n",
      "Epoch 8/25\n",
      "63756/63756 [==============================] - 187s 3ms/step - loss: 2.8961 - acc: 0.3555 - val_loss: 2.6602 - val_acc: 0.4122\n",
      "Epoch 9/25\n",
      "63756/63756 [==============================] - 188s 3ms/step - loss: 2.8136 - acc: 0.3661 - val_loss: 2.6489 - val_acc: 0.4118\n",
      "Epoch 10/25\n",
      "63756/63756 [==============================] - 187s 3ms/step - loss: 2.7338 - acc: 0.3827 - val_loss: 2.6448 - val_acc: 0.4122\n",
      "Epoch 11/25\n",
      "63756/63756 [==============================] - 188s 3ms/step - loss: 2.6741 - acc: 0.3943 - val_loss: 2.5341 - val_acc: 0.4310\n",
      "Epoch 12/25\n",
      "63756/63756 [==============================] - 188s 3ms/step - loss: 2.6104 - acc: 0.4035 - val_loss: 2.5931 - val_acc: 0.4275\n",
      "Epoch 13/25\n",
      "63756/63756 [==============================] - 187s 3ms/step - loss: 2.5376 - acc: 0.4164 - val_loss: 2.4776 - val_acc: 0.4483\n",
      "Epoch 14/25\n",
      "63756/63756 [==============================] - 188s 3ms/step - loss: 2.5000 - acc: 0.4241 - val_loss: 2.4435 - val_acc: 0.4527\n",
      "Epoch 15/25\n",
      "63756/63756 [==============================] - 187s 3ms/step - loss: 2.4501 - acc: 0.4337 - val_loss: 2.4302 - val_acc: 0.4566\n",
      "Epoch 16/25\n",
      "63756/63756 [==============================] - 204s 3ms/step - loss: 2.4010 - acc: 0.4390 - val_loss: 2.5537 - val_acc: 0.4448\n",
      "Epoch 17/25\n",
      "63756/63756 [==============================] - 194s 3ms/step - loss: 2.3682 - acc: 0.4442 - val_loss: 2.4245 - val_acc: 0.4543\n",
      "Epoch 18/25\n",
      "63756/63756 [==============================] - 194s 3ms/step - loss: 2.3248 - acc: 0.4545 - val_loss: 2.4074 - val_acc: 0.4611\n",
      "Epoch 19/25\n",
      "63756/63756 [==============================] - 194s 3ms/step - loss: 2.3023 - acc: 0.4575 - val_loss: 2.5311 - val_acc: 0.4551\n",
      "Epoch 20/25\n",
      "63756/63756 [==============================] - 195s 3ms/step - loss: 2.2668 - acc: 0.4666 - val_loss: 2.4395 - val_acc: 0.4595\n",
      "Epoch 21/25\n",
      "63756/63756 [==============================] - 195s 3ms/step - loss: 2.2374 - acc: 0.4667 - val_loss: 2.5059 - val_acc: 0.4431\n",
      "Epoch 22/25\n",
      "63756/63756 [==============================] - 194s 3ms/step - loss: 2.2142 - acc: 0.4732 - val_loss: 2.5120 - val_acc: 0.4611\n",
      "Epoch 23/25\n",
      "63756/63756 [==============================] - 193s 3ms/step - loss: 2.1890 - acc: 0.4791 - val_loss: 2.5023 - val_acc: 0.4576\n",
      "Epoch 24/25\n",
      "63756/63756 [==============================] - 192s 3ms/step - loss: 2.1735 - acc: 0.4805 - val_loss: 2.4243 - val_acc: 0.4651\n",
      "Epoch 25/25\n",
      "63756/63756 [==============================] - 193s 3ms/step - loss: 2.1427 - acc: 0.4886 - val_loss: 2.4300 - val_acc: 0.4590\n",
      "Test loss: 2.429988383678415\n",
      "Test accuracy: 0.45899993726454635\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 63756 samples, validate on 15939 samples\n",
      "Epoch 1/25\n",
      "63756/63756 [==============================] - 196s 3ms/step - loss: 2.1277 - acc: 0.4908 - val_loss: 2.6702 - val_acc: 0.4616\n",
      "Epoch 2/25\n",
      "63756/63756 [==============================] - 197s 3ms/step - loss: 2.1094 - acc: 0.4931 - val_loss: 2.5161 - val_acc: 0.4705\n",
      "Epoch 3/25\n",
      "63756/63756 [==============================] - 198s 3ms/step - loss: 2.1006 - acc: 0.4975 - val_loss: 2.5359 - val_acc: 0.4448\n",
      "Epoch 4/25\n",
      "63756/63756 [==============================] - 196s 3ms/step - loss: 2.0888 - acc: 0.4982 - val_loss: 2.4050 - val_acc: 0.4631\n",
      "Epoch 5/25\n",
      "63756/63756 [==============================] - 195s 3ms/step - loss: 2.0710 - acc: 0.4999 - val_loss: 2.4827 - val_acc: 0.4608\n",
      "Epoch 6/25\n",
      "63756/63756 [==============================] - 196s 3ms/step - loss: 2.0742 - acc: 0.5002 - val_loss: 2.5399 - val_acc: 0.4493\n",
      "Epoch 7/25\n",
      "63756/63756 [==============================] - 196s 3ms/step - loss: 2.0478 - acc: 0.5049 - val_loss: 2.4220 - val_acc: 0.4606\n",
      "Epoch 8/25\n",
      "63756/63756 [==============================] - 196s 3ms/step - loss: 2.0409 - acc: 0.5082 - val_loss: 2.5979 - val_acc: 0.4565\n",
      "Epoch 9/25\n",
      "63756/63756 [==============================] - 196s 3ms/step - loss: 2.0216 - acc: 0.5124 - val_loss: 2.6334 - val_acc: 0.4708\n",
      "Epoch 10/25\n",
      "63756/63756 [==============================] - 195s 3ms/step - loss: 2.0203 - acc: 0.5105 - val_loss: 2.5841 - val_acc: 0.4658\n",
      "Epoch 11/25\n",
      "63756/63756 [==============================] - 196s 3ms/step - loss: 2.0093 - acc: 0.5147 - val_loss: 2.4472 - val_acc: 0.4557\n",
      "Epoch 12/25\n",
      "63756/63756 [==============================] - 196s 3ms/step - loss: 2.0013 - acc: 0.5150 - val_loss: 2.4464 - val_acc: 0.4616\n",
      "Epoch 13/25\n",
      "63756/63756 [==============================] - 195s 3ms/step - loss: 1.9916 - acc: 0.5180 - val_loss: 2.4201 - val_acc: 0.4621\n",
      "Epoch 14/25\n",
      "63756/63756 [==============================] - 196s 3ms/step - loss: 1.9965 - acc: 0.5149 - val_loss: 2.5079 - val_acc: 0.4718\n",
      "Epoch 15/25\n",
      "63756/63756 [==============================] - 196s 3ms/step - loss: 1.9736 - acc: 0.5184 - val_loss: 2.5023 - val_acc: 0.4656\n",
      "Epoch 16/25\n",
      "63756/63756 [==============================] - 196s 3ms/step - loss: 1.9678 - acc: 0.5214 - val_loss: 2.4397 - val_acc: 0.4601\n",
      "Epoch 17/25\n",
      "63756/63756 [==============================] - 197s 3ms/step - loss: 1.9740 - acc: 0.5198 - val_loss: 2.4630 - val_acc: 0.4506\n",
      "Epoch 18/25\n",
      "63756/63756 [==============================] - 196s 3ms/step - loss: 1.9575 - acc: 0.5259 - val_loss: 2.5454 - val_acc: 0.4506\n",
      "Epoch 19/25\n",
      "63756/63756 [==============================] - 196s 3ms/step - loss: 1.9556 - acc: 0.5244 - val_loss: 2.4366 - val_acc: 0.4569\n",
      "Epoch 20/25\n",
      "63756/63756 [==============================] - 196s 3ms/step - loss: 1.9557 - acc: 0.5253 - val_loss: 2.6279 - val_acc: 0.4695\n",
      "Epoch 21/25\n",
      "63756/63756 [==============================] - 196s 3ms/step - loss: 1.9384 - acc: 0.5266 - val_loss: 2.7517 - val_acc: 0.4699\n",
      "Epoch 22/25\n",
      "63756/63756 [==============================] - 197s 3ms/step - loss: 1.9352 - acc: 0.5298 - val_loss: 2.4825 - val_acc: 0.4677\n",
      "Epoch 23/25\n",
      "63756/63756 [==============================] - 196s 3ms/step - loss: 1.9472 - acc: 0.5281 - val_loss: 2.5346 - val_acc: 0.4660\n",
      "Epoch 24/25\n",
      "63756/63756 [==============================] - 196s 3ms/step - loss: 1.9413 - acc: 0.5289 - val_loss: 2.4444 - val_acc: 0.4697\n",
      "Epoch 25/25\n",
      "63756/63756 [==============================] - 196s 3ms/step - loss: 1.9246 - acc: 0.5300 - val_loss: 2.4237 - val_acc: 0.4687\n",
      "Test loss: 2.423663345751316\n",
      "Test accuracy: 0.4687245122065126\n"
     ]
    }
   ],
   "source": [
    "# More epochs\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=25,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('quickdraw_all.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
